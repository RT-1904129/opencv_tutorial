{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I write all traker name in dictionery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrDict={'csrt':cv2.TrackerCSRT_create,\n",
    "       'kcf':cv2.TrackerKCF_create,\n",
    "       'boosting':cv2.TrackerBoosting_create,\n",
    "       'mil':cv2.TrackerMIL_create,\n",
    "       'tld': cv2.TrackerTLD_create,\n",
    "       'medianflow':cv2.TrackerMedianFlow_create,\n",
    "       'mosse':cv2.TrackerMOSSE_create}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker=TrDict['csrt']()\n",
    "#its means is cv2.TrackerCSRT_create()\n",
    "#CSRT traker work well with moving object so we can use it better there are many traker which proferm well with different work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=0 \n",
    "#its for our one camera if we want to read any vedio than provide path for that vedio file\n",
    "Cap=cv2.VideoCapture(path)\n",
    "ret,frame=Cap.read()\n",
    "# Flip a 2D array. \"1\" means flipping around y-axis\n",
    "frame = cv2.flip(frame, 1)\n",
    "cv2.imshow('Frame',frame)\n",
    "#now we select region of interest\n",
    "bb=cv2.selectROI('Frame',frame)\n",
    "#cv2.selectROI(window name,frame)\n",
    "#now we initilize the traker\n",
    "tracker.init(frame,bb)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame=Cap.read()\n",
    "    # Flip a 2D array. \"1\" means flipping around y-axis\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    (success,box)=tracker.update(frame)\n",
    "    if success:\n",
    "        x,y,w,h=[int(point) for point in box]\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    if cv2.waitKey(1)==ord('q'): # wen we press q key than it realse the webcam\n",
    "        break\n",
    "\n",
    "Cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we focus on traking single objects we can learn traking for multipe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
